{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4c78b30",
   "metadata": {},
   "source": [
    "# Deep Learning Model Evaluation\n",
    "## Stage 07: PyTorch DNN Model Performance Evaluation & MLflow Logging\n",
    "\n",
    "This notebook evaluates the trained Deep Neural Network and logs results to MLflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a79b2a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382dac58",
   "metadata": {},
   "source": [
    "## 1. Configuration Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e94bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DeepModelEvaluationConfig:\n",
    "    root_dir: Path\n",
    "    test_data_path: Path\n",
    "    model_path: Path\n",
    "    scaler_path: Path\n",
    "    model_config_path: Path\n",
    "    all_params: dict\n",
    "    metric_file_name: Path\n",
    "    target_column: str\n",
    "    mlflow_uri: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2d57b5",
   "metadata": {},
   "source": [
    "## 2. Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f72985",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5793619",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,\n",
    "            params_filepath=PARAMS_FILE_PATH,\n",
    "            schema_filepath=SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_deep_model_evaluation_config(self) -> DeepModelEvaluationConfig:\n",
    "        config = self.config.deep_model_evaluation\n",
    "        params = self.params.DeepModel\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        deep_model_evaluation_config = DeepModelEvaluationConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_path=config.model_path,\n",
    "            scaler_path=config.scaler_path,\n",
    "            model_config_path=config.model_config_path,\n",
    "            all_params=params,\n",
    "            metric_file_name=config.metric_file_name,\n",
    "            target_column=schema.name,\n",
    "            mlflow_uri=\"https://dagshub.com/Loza-Tadesse/VinoPredict.mlflow\"\n",
    "        )\n",
    "\n",
    "        return deep_model_evaluation_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a253d011",
   "metadata": {},
   "source": [
    "## 3. Model Architecture & Evaluation Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67df8ba2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import json\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from mlProject import logger\n",
    "from mlProject.utils.common import save_json\n",
    "import mlflow\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eea3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoPriceNet(nn.Module):\n",
    "    \"\"\"Neural Network for Cryptocurrency Price Prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_layers, dropout_rate=0.2):\n",
    "        super(CryptoPriceNet, self).__init__()\n",
    "        \n",
    "        layers_list = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Hidden layers\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers_list.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers_list.append(nn.ReLU())\n",
    "            layers_list.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers_list.append(nn.Linear(prev_size, 1))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers_list)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "798e255f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepModelEvaluation:\n",
    "    def __init__(self, config: DeepModelEvaluationConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    def eval_metrics(self, actual, pred):\n",
    "        rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "        mae = mean_absolute_error(actual, pred)\n",
    "        r2 = r2_score(actual, pred)\n",
    "        return rmse, mae, r2\n",
    "\n",
    "    def log_into_mlflow(self):\n",
    "        try:\n",
    "            # Load test data\n",
    "            test_data = pd.read_csv(self.config.test_data_path)\n",
    "            \n",
    "            # Load model configuration\n",
    "            with open(self.config.model_config_path, 'r') as f:\n",
    "                model_config = json.load(f)\n",
    "            \n",
    "            # Load scaler\n",
    "            scaler = joblib.load(self.config.scaler_path)\n",
    "            \n",
    "            # Initialize model architecture\n",
    "            model = CryptoPriceNet(\n",
    "                input_size=model_config['input_size'],\n",
    "                hidden_layers=model_config['hidden_layers'],\n",
    "                dropout_rate=model_config['dropout_rate']\n",
    "            ).to(self.device)\n",
    "            \n",
    "            # Load trained weights\n",
    "            model.load_state_dict(torch.load(self.config.model_path, map_location=self.device))\n",
    "            model.eval()\n",
    "            \n",
    "            # Prepare test data\n",
    "            test_x = test_data.drop([self.config.target_column], axis=1)\n",
    "            test_y = test_data[self.config.target_column]\n",
    "            \n",
    "            # Scale features\n",
    "            test_x_scaled = scaler.transform(test_x)\n",
    "            test_x_tensor = torch.FloatTensor(test_x_scaled).to(self.device)\n",
    "            \n",
    "            # Make predictions\n",
    "            with torch.no_grad():\n",
    "                predicted_qualities = model(test_x_tensor).cpu().numpy().flatten()\n",
    "            \n",
    "            # Calculate metrics\n",
    "            (rmse, mae, r2) = self.eval_metrics(test_y, predicted_qualities)\n",
    "            \n",
    "            # Save metrics locally\n",
    "            scores = {\"rmse\": rmse, \"mae\": mae, \"r2\": r2}\n",
    "            save_json(path=Path(self.config.metric_file_name), data=scores)\n",
    "            \n",
    "            # MLflow logging\n",
    "            mlflow.set_registry_uri(self.config.mlflow_uri)\n",
    "            tracking_url_type_store = urlparse(mlflow.get_tracking_uri()).scheme\n",
    "            \n",
    "            # Set or create experiment\n",
    "            experiment_name = \"Deep_Learning_CryptoPredict\"\n",
    "            try:\n",
    "                mlflow.create_experiment(experiment_name)\n",
    "            except mlflow.exceptions.MlflowException:\n",
    "                pass\n",
    "            \n",
    "            mlflow.set_experiment(experiment_name)\n",
    "            \n",
    "            # Create unique run name\n",
    "            import time\n",
    "            run_name = f\"deep_model_eval_{int(time.time())}\"\n",
    "            \n",
    "            with mlflow.start_run(run_name=run_name):\n",
    "                # Log parameters\n",
    "                params_to_log = {\n",
    "                    \"model_type\": \"PyTorch_Neural_Network\",\n",
    "                    \"architecture\": str(model_config['hidden_layers']),\n",
    "                    \"device\": str(self.device),\n",
    "                    \"input_size\": model_config['input_size'],\n",
    "                    \"dropout_rate\": model_config['dropout_rate']\n",
    "                }\n",
    "                \n",
    "                for key, value in params_to_log.items():\n",
    "                    try:\n",
    "                        mlflow.log_param(key, value)\n",
    "                    except mlflow.exceptions.MlflowException as param_e:\n",
    "                        logger.warning(f\"Could not log parameter {key}: {param_e}\")\n",
    "                \n",
    "                # Log metrics\n",
    "                mlflow.log_metric(\"rmse\", rmse)\n",
    "                mlflow.log_metric(\"mae\", mae)\n",
    "                mlflow.log_metric(\"r2\", r2)\n",
    "                \n",
    "                # Register model\n",
    "                if tracking_url_type_store != \"file\":\n",
    "                    mlflow.pytorch.log_model(model, \"model\", registered_model_name=\"DeepCryptoPriceModel\")\n",
    "                else:\n",
    "                    mlflow.pytorch.log_model(model, \"model\")\n",
    "            \n",
    "            logger.info(f\"Deep model evaluation completed. RMSE: {rmse:.4f}, MAE: {mae:.4f}, R2: {r2:.4f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error during deep model evaluation: {str(e)}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05de8ba9",
   "metadata": {},
   "source": [
    "## 4. Execute Evaluation Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "342081c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    deep_model_evaluation_config = config.get_deep_model_evaluation_config()\n",
    "    deep_model_evaluation = DeepModelEvaluation(config=deep_model_evaluation_config)\n",
    "    deep_model_evaluation.log_into_mlflow()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744d6973",
   "metadata": {},
   "source": [
    "## 5. Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7df8bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load metrics\n",
    "with open('artifacts/deep_model_evaluation/metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"Deep Learning Model Performance:\")\n",
    "print(f\"RMSE: {metrics['rmse']:.4f}\")\n",
    "print(f\"MAE: {metrics['mae']:.4f}\")\n",
    "print(f\"R²: {metrics['r2']:.4f}\")\n",
    "\n",
    "# Visualize predictions vs actual\n",
    "test_data = pd.read_csv('artifacts/data_transformation/test.csv')\n",
    "test_x = test_data.drop(['target_price_1h'], axis=1)\n",
    "test_y = test_data['target_price_1h']\n",
    "\n",
    "# Load model and make predictions\n",
    "scaler = joblib.load('artifacts/deep_model_trainer/scaler.joblib')\n",
    "with open('artifacts/deep_model_trainer/model_config.json', 'r') as f:\n",
    "    model_config = json.load(f)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = CryptoPriceNet(\n",
    "    input_size=model_config['input_size'],\n",
    "    hidden_layers=model_config['hidden_layers'],\n",
    "    dropout_rate=model_config['dropout_rate']\n",
    ").to(device)\n",
    "\n",
    "model.load_state_dict(torch.load('artifacts/deep_model_trainer/best_deep_model.pth', map_location=device))\n",
    "model.eval()\n",
    "\n",
    "test_x_scaled = scaler.transform(test_x)\n",
    "test_x_tensor = torch.FloatTensor(test_x_scaled).to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    predictions = model(test_x_tensor).cpu().numpy().flatten()\n",
    "\n",
    "# Plot predictions\n",
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.scatter(test_y, predictions, alpha=0.5)\n",
    "plt.plot([test_y.min(), test_y.max()], [test_y.min(), test_y.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Price')\n",
    "plt.ylabel('Predicted Price')\n",
    "plt.title('Actual vs Predicted Prices')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "residuals = test_y - predictions\n",
    "plt.hist(residuals, bins=50, edgecolor='black')\n",
    "plt.xlabel('Residuals (Actual - Predicted)')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Residuals Distribution')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
