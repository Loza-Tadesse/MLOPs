{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddd7ec4b",
   "metadata": {},
   "source": [
    "# Deep Learning Model Training (DNN)\n",
    "## Stage 06: PyTorch Neural Network for Cryptocurrency Price Prediction\n",
    "\n",
    "This notebook explores training a Deep Neural Network (DNN) using PyTorch for predicting cryptocurrency prices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b69079",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('../')\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8deebd7",
   "metadata": {},
   "source": [
    "## 1. Configuration Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45cfa9ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class DeepModelTrainerConfig:\n",
    "    root_dir: Path\n",
    "    train_data_path: Path\n",
    "    test_data_path: Path\n",
    "    model_name: str\n",
    "    hidden_layers: list\n",
    "    dropout_rate: float\n",
    "    learning_rate: float\n",
    "    batch_size: int\n",
    "    epochs: int\n",
    "    early_stopping_patience: int\n",
    "    target_column: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a3e5d46",
   "metadata": {},
   "source": [
    "## 2. Configuration Manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6782a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlProject.constants import *\n",
    "from mlProject.utils.common import read_yaml, create_directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "620dfc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "            self,\n",
    "            config_filepath=CONFIG_FILE_PATH,\n",
    "            params_filepath=PARAMS_FILE_PATH,\n",
    "            schema_filepath=SCHEMA_FILE_PATH):\n",
    "\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        self.schema = read_yaml(schema_filepath)\n",
    "\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "    def get_deep_model_trainer_config(self) -> DeepModelTrainerConfig:\n",
    "        config = self.config.deep_model_trainer\n",
    "        params = self.params.DeepModel\n",
    "        schema = self.schema.TARGET_COLUMN\n",
    "\n",
    "        create_directories([config.root_dir])\n",
    "\n",
    "        deep_model_trainer_config = DeepModelTrainerConfig(\n",
    "            root_dir=config.root_dir,\n",
    "            train_data_path=config.train_data_path,\n",
    "            test_data_path=config.test_data_path,\n",
    "            model_name=config.model_name,\n",
    "            hidden_layers=params.hidden_layers,\n",
    "            dropout_rate=params.dropout_rate,\n",
    "            learning_rate=params.learning_rate,\n",
    "            batch_size=params.batch_size,\n",
    "            epochs=params.epochs,\n",
    "            early_stopping_patience=params.early_stopping_patience,\n",
    "            target_column=schema.name\n",
    "        )\n",
    "\n",
    "        return deep_model_trainer_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8f8080a",
   "metadata": {},
   "source": [
    "## 3. Deep Neural Network Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4347e7d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "import json\n",
    "from mlProject import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681380d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoPriceNet(nn.Module):\n",
    "    \"\"\"Neural Network for Cryptocurrency Price Prediction\"\"\"\n",
    "    \n",
    "    def __init__(self, input_size, hidden_layers, dropout_rate=0.2):\n",
    "        super(CryptoPriceNet, self).__init__()\n",
    "        \n",
    "        layers_list = []\n",
    "        prev_size = input_size\n",
    "        \n",
    "        # Hidden layers\n",
    "        for hidden_size in hidden_layers:\n",
    "            layers_list.append(nn.Linear(prev_size, hidden_size))\n",
    "            layers_list.append(nn.ReLU())\n",
    "            layers_list.append(nn.Dropout(dropout_rate))\n",
    "            prev_size = hidden_size\n",
    "        \n",
    "        # Output layer\n",
    "        layers_list.append(nn.Linear(prev_size, 1))\n",
    "        \n",
    "        self.network = nn.Sequential(*layers_list)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce6146a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoDataset(Dataset):\n",
    "    \"\"\"Custom Dataset for Cryptocurrency Data\"\"\"\n",
    "    \n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets).reshape(-1, 1)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.features)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644bbdf4",
   "metadata": {},
   "source": [
    "## 4. Deep Model Trainer Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025a9f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DeepModelTrainer:\n",
    "    def __init__(self, config: DeepModelTrainerConfig):\n",
    "        self.config = config\n",
    "        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        logger.info(f\"Using device: {self.device}\")\n",
    "        \n",
    "    def train(self):\n",
    "        \"\"\"Train Deep Neural Network model\"\"\"\n",
    "        try:\n",
    "            # Load data\n",
    "            logger.info(\"Loading training and test data...\")\n",
    "            train_data = pd.read_csv(self.config.train_data_path)\n",
    "            test_data = pd.read_csv(self.config.test_data_path)\n",
    "            \n",
    "            # Prepare features and target\n",
    "            train_x = train_data.drop([self.config.target_column], axis=1)\n",
    "            test_x = test_data.drop([self.config.target_column], axis=1)\n",
    "            train_y = train_data[self.config.target_column].values\n",
    "            test_y = test_data[self.config.target_column].values\n",
    "            \n",
    "            input_size = train_x.shape[1]\n",
    "            logger.info(f\"Input features: {input_size}\")\n",
    "            logger.info(f\"Training samples: {len(train_x)}, Test samples: {len(test_x)}\")\n",
    "            \n",
    "            # Scale features\n",
    "            logger.info(\"Scaling features...\")\n",
    "            scaler = StandardScaler()\n",
    "            train_x_scaled = scaler.fit_transform(train_x)\n",
    "            test_x_scaled = scaler.transform(test_x)\n",
    "            \n",
    "            # Save scaler\n",
    "            scaler_path = os.path.join(self.config.root_dir, 'scaler.joblib')\n",
    "            joblib.dump(scaler, scaler_path)\n",
    "            logger.info(f\"Scaler saved to {scaler_path}\")\n",
    "            \n",
    "            # Create datasets and dataloaders\n",
    "            train_dataset = CryptoDataset(train_x_scaled, train_y)\n",
    "            test_dataset = CryptoDataset(test_x_scaled, test_y)\n",
    "            \n",
    "            train_loader = DataLoader(\n",
    "                train_dataset, \n",
    "                batch_size=self.config.batch_size,\n",
    "                shuffle=True\n",
    "            )\n",
    "            test_loader = DataLoader(\n",
    "                test_dataset,\n",
    "                batch_size=self.config.batch_size,\n",
    "                shuffle=False\n",
    "            )\n",
    "            \n",
    "            # Initialize model\n",
    "            model = CryptoPriceNet(\n",
    "                input_size=input_size,\n",
    "                hidden_layers=self.config.hidden_layers,\n",
    "                dropout_rate=self.config.dropout_rate\n",
    "            ).to(self.device)\n",
    "            \n",
    "            logger.info(f\"Model Architecture:\\n{model}\")\n",
    "            \n",
    "            # Loss and optimizer\n",
    "            criterion = nn.MSELoss()\n",
    "            optimizer = optim.Adam(\n",
    "                model.parameters(), \n",
    "                lr=self.config.learning_rate,\n",
    "                weight_decay=1e-5\n",
    "            )\n",
    "            scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer, mode='min', factor=0.5, patience=5\n",
    "            )\n",
    "            \n",
    "            # Training loop\n",
    "            best_loss = float('inf')\n",
    "            patience_counter = 0\n",
    "            train_losses = []\n",
    "            test_losses = []\n",
    "            \n",
    "            logger.info(\"Starting training...\")\n",
    "            for epoch in range(self.config.epochs):\n",
    "                # Training phase\n",
    "                model.train()\n",
    "                train_loss = 0.0\n",
    "                \n",
    "                for batch_features, batch_targets in train_loader:\n",
    "                    batch_features = batch_features.to(self.device)\n",
    "                    batch_targets = batch_targets.to(self.device)\n",
    "                    \n",
    "                    # Forward pass\n",
    "                    optimizer.zero_grad()\n",
    "                    outputs = model(batch_features)\n",
    "                    loss = criterion(outputs, batch_targets)\n",
    "                    \n",
    "                    # Backward pass\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "                    \n",
    "                    train_loss += loss.item()\n",
    "                \n",
    "                train_loss /= len(train_loader)\n",
    "                train_losses.append(train_loss)\n",
    "                \n",
    "                # Validation phase\n",
    "                model.eval()\n",
    "                test_loss = 0.0\n",
    "                \n",
    "                with torch.no_grad():\n",
    "                    for batch_features, batch_targets in test_loader:\n",
    "                        batch_features = batch_features.to(self.device)\n",
    "                        batch_targets = batch_targets.to(self.device)\n",
    "                        \n",
    "                        outputs = model(batch_features)\n",
    "                        loss = criterion(outputs, batch_targets)\n",
    "                        test_loss += loss.item()\n",
    "                \n",
    "                test_loss /= len(test_loader)\n",
    "                test_losses.append(test_loss)\n",
    "                \n",
    "                # Learning rate scheduling\n",
    "                scheduler.step(test_loss)\n",
    "                \n",
    "                # Log progress\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    logger.info(\n",
    "                        f\"Epoch [{epoch+1}/{self.config.epochs}] \"\n",
    "                        f\"Train Loss: {train_loss:.6f}, Test Loss: {test_loss:.6f}\"\n",
    "                    )\n",
    "                \n",
    "                # Early stopping\n",
    "                if test_loss < best_loss:\n",
    "                    best_loss = test_loss\n",
    "                    patience_counter = 0\n",
    "                    \n",
    "                    # Save best model\n",
    "                    model_path = os.path.join(self.config.root_dir, self.config.model_name)\n",
    "                    torch.save(model.state_dict(), model_path)\n",
    "                    logger.info(f\"Best model saved with test loss: {best_loss:.6f}\")\n",
    "                else:\n",
    "                    patience_counter += 1\n",
    "                    \n",
    "                if patience_counter >= self.config.early_stopping_patience:\n",
    "                    logger.info(f\"Early stopping at epoch {epoch+1}\")\n",
    "                    break\n",
    "            \n",
    "            # Save model configuration\n",
    "            model_config = {\n",
    "                'input_size': input_size,\n",
    "                'hidden_layers': self.config.hidden_layers,\n",
    "                'dropout_rate': self.config.dropout_rate,\n",
    "                'feature_names': list(train_x.columns)\n",
    "            }\n",
    "            \n",
    "            config_path = os.path.join(self.config.root_dir, 'model_config.json')\n",
    "            with open(config_path, 'w') as f:\n",
    "                json.dump(model_config, f, indent=4)\n",
    "            logger.info(f\"Model config saved to {config_path}\")\n",
    "            \n",
    "            # Save training history\n",
    "            history = {\n",
    "                'train_losses': train_losses,\n",
    "                'test_losses': test_losses,\n",
    "                'best_loss': best_loss,\n",
    "                'epochs_trained': len(train_losses)\n",
    "            }\n",
    "            \n",
    "            history_path = os.path.join(self.config.root_dir, 'training_history.json')\n",
    "            with open(history_path, 'w') as f:\n",
    "                json.dump(history, f, indent=4)\n",
    "            logger.info(f\"Training history saved to {history_path}\")\n",
    "            \n",
    "            logger.info(\"Training completed successfully!\")\n",
    "            logger.info(f\"Best test loss: {best_loss:.6f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.exception(f\"Error during deep model training: {str(e)}\")\n",
    "            raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "778b0b60",
   "metadata": {},
   "source": [
    "## 5. Execute Training Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc81094f",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    deep_model_trainer_config = config.get_deep_model_trainer_config()\n",
    "    deep_model_trainer = DeepModelTrainer(config=deep_model_trainer_config)\n",
    "    deep_model_trainer.train()\n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95c228e7",
   "metadata": {},
   "source": [
    "## 6. Visualize Training History"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbc0bfae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load training history\n",
    "with open('artifacts/deep_model_trainer/training_history.json', 'r') as f:\n",
    "    history = json.load(f)\n",
    "\n",
    "# Plot losses\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history['train_losses'], label='Train Loss')\n",
    "plt.plot(history['test_losses'], label='Test Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Training and Test Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history['test_losses'], label='Test Loss', color='orange')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss (MSE)')\n",
    "plt.title('Test Loss Over Time')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(f\"Best Loss: {history['best_loss']:.6f}\")\n",
    "print(f\"Epochs Trained: {history['epochs_trained']}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
